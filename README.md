# Lib description

## Установка.
В активном окружении выполнить из корня:
```
pip install -e [dev,test]
```
(если `zsh`)
```
pip install -e \."[dev,tests]"
```

## Настройка параметров и запуск
`config.yaml` позволяет выбирать конфигурацию для запуска обучения модели. Соответвсующие параметры будут переданы в `train` скрипт и при создании модели. Для модели классификации нужно иметь обученную модель `VAE`.

После настройки параметров скрипт обучения можно запустить командой `train`

```
usage: train [-h] (--vae | --cls)

optional arguments:
  -h, --help  show this help message and exit
  --vae       run train pipline for VAE model using config.yml file.
  --cls       run train pipline for classification model using config.yml file.
```

Если нет данных, то они будут автоматически скачаны в папке `assets`.

# VAE

## Реализация
![arch](/notebooks/VAE.png)

## Латентное пространство
Размерность латентного простравнства выбиралось сравнением обученных моделей. Модели с меньшим размером показали себя лучше с т.з. `loss`, восстановленные изображения не показали особой разницы. На классификации лучшие метрики показала большая модель, обученная на 100 эпох с аугментацией.

## Reconstruction

![big_model](/notebooks/big_aug_reconstruction.png)

*Пример рекнструкции от большой модели (latent_szie = 128) с аугментацией.*

![small_model](/notebooks/small_reconstruction.png)

*Пример рекнструкции от малой модели (latent_szie = 64).*

## Подробнее 
Более подробнее все опробованные конфигурации моделей в [ноутбуке](/notebooks/MIL_vae.ipynb). Там же сравнительные метрики.

- `mse` по всем пикселям. Среднее и медианные значения на различных картинках в датасете: 1500, 1300
- `log(cosh(x))` по всем пикселям. Среднее и медианные значения:  случайно удалил. Около 1500

Лучшие метрики:
- mse: 108; log(cosh): 346
    - latent_size: 64
    - epochs: 50
    - augmentation: False
    - loss: mse

- mse: 110; log(cosh): 343 
    - latent_size: 64
    - epochs: 50
    - augmentation: False
    - loss: log(cosh)

- mse: 116; log(cosh): 355
    - latent_size: 128
    - epochs: 100
    - augmentation: True
    - loss: mse

# Classification
На обученных моделях VAE попробовал обучить классификаторы. Метрики, по которым сравнивал - стандартный `classification_report` из `scikit-learn`.

Лучшая модель:
```
precision    recall  f1-score   support

       plane       0.57      0.60      0.59      1000
         car       0.63      0.63      0.63      1000
        bird       0.39      0.36      0.38      1000
         cat       0.34      0.28      0.31      1000
        deer       0.42      0.40      0.41      1000
         dog       0.44      0.38      0.41      1000
        frog       0.49      0.66      0.56      1000
       horse       0.59      0.57      0.58      1000
        ship       0.61      0.66      0.64      1000
       truck       0.57      0.54      0.56      1000

    accuracy                           0.51     10000
   macro avg       0.51      0.51      0.51     10000
weighted avg       0.51      0.51      0.51     10000
```
Чуть более подробно в [ноутбуке](/notebooks/classification.ipynb).

# Улучшения и выводы

1. Стандарные улучшение - попробовать Байесовскую оптимизацию гиперпараметров (размерности латентного пространства, например). Вообще в задаче я мало успел потюнить параметры из-за ограниченной возможности пользоваться мощным "железом".

2. Архитектура VAE достаточно старая. Построение латентного пространства с непрерывным распределением даёт очень размытые изображения. Потому очевидным улучшением могла бы стать модель с дискретным латентным пространством VQVAE. Более того, она не требует внесения слишком больших изменений в текущую структуру.

3. Классификатор стандарный и обучался без тюнинга параметров и аугментации. Так что тут есть ещё куда работать. Так же можно на полученных метриках подробнее изучить данные и понять, почему те или иные классы могу проседать.

4. Скрипты позволяют обучать модели, но не так гибко, как хотелось бы. Следует разнести конфиги для классификации и автоэнкодера, а так же полезно добавить `DVC(pipeline)/MLflow` + `s3 storage` для сохранения артифактов и версионирования моделей.

<hr>
<hr>

# Тестовое задание
Написать и обучить модель-автокодировщик на датасете на выбор: CIFAR10, CIFAR100.
Обучить модель-классификатор на латентных представлениях обученного автокодировщика.


### Рекомендуемые шаги для выполнения задания

**Шаг 1.** Подготовка инфраструктуры.

Создание окружения, организация структуры репозитория, загрузка датасетов.

**Шаг 2.** Реализовать модель-автоенкодер.

Выбрать архитектуру и реализовать ее совместно с процедурой обучения, подходящей для выбранного датасета.
Важно обратить внимание на выбор размерность скрытого состояния. Обосновать свой выбор.

**Шаг 3.** Обучить автоенкодер.

Нужно обучить реализованную архитектуру на скаченном датасете.
Оценить качество работы модели.

**Шаг 4.** Реализовать модель-классификатор.

Реализовать небольшую модель классификатор на скрытых представлениях уже обученного автоенкодера.
Реализовать пайплайн обучения данной модели.

**Шаг 5.** Обучение модели классификатора и визуализация результатов.

На этом шаге требуется обучить модель классификатор и оценить ее качество.
Подумайте, в каком виде было бы удобно провести демонстрацию результатов?

**Шаг 6.** Выводы и идеи.

Проведите анализ результатов, сделайте несколько выводов на основе полученных рузультатов.
Предложите свои идеи, как можно улучшить текущие результаты.


### Что будет оцениваться?
1. Реализация и оформление кода на github.
2. Соответствие решения тестовому заданию.
3. Оформление результатов.
4. Любые релевантные мысли, идеи и соображения.
5. Будет плюсом проведение нескольких экспериментов и их анализ.
